{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE-VISUALIZATION\n",
    "    We would do TSNE-visualization of MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_length = 1000 # This \"i\" is the number of datapoints we are sampling\n",
    "# We would perform TSNE on only first 1000 points as performing TSNE takes alot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Loosely inspired by http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "which is GPL licensed.\n",
    "\"\"\"\n",
    "\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, '../Data/train-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, '../Data/train-labels.idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)\n",
    "\n",
    "def show(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = list(read(dataset='training',path='.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noAg/EBThB4Ii/EBQ/w/XV2GigVP4cQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1cd45547f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label, pixel = train_data[0]\n",
    "show(pixel)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "    In the cell below we are flatteing the data to a row(in data_all) and treating each row as a datapoint and the lables for each datapoint would be in label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_all = []\n",
    "label_all = []\n",
    "for i in range(0,60000):\n",
    "    data_all.append(train_data[i][1].flatten())\n",
    "    label_all.append(train_data[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking up only a few first points. On these points we would do dimensionality reduction and visualization by TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 784), (1000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_all[0:sample_length]\n",
    "data = np.array(data)\n",
    "label = label_all[0:sample_length]\n",
    "label = np.array(label)\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down in the cell we are Standardizing the data column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 784), -1.1084466677857563e-12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stan_data = StandardScaler().fit_transform(data)\n",
    "stan_data.shape, np.sum(stan_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "dist_color = [\"#e6194b\", \"#3cb44b\", \"#ffe119\", \"#0082c8\", \"#46f0f0\",\\\n",
    "\"#911eb4\", '#aa6e28', '#000000','#f032e6','#aaffc3']\n",
    "# We would visualize in 2D thus n_components=2\n",
    "for i in range(5,801):\n",
    "    model = TSNE(n_components=2,perplexity=i)\n",
    "    X_embedded = model.fit_transform(stan_data)\n",
    "\n",
    "    X_embedded = np.array([X_embedded[:,0],X_embedded[:,1],label])\n",
    "\n",
    "    X_embedded = X_embedded.T\n",
    "\n",
    "    # Preparing a dataframe of the embedded points with class lables\n",
    "    df = pd.DataFrame(data=X_embedded\\\n",
    "    ,columns=['PC1','PC2','label'])\n",
    "\n",
    "    sns.FacetGrid(df, hue=\"label\",aspect=2,palette=sns.color_palette(dist_color), size=6) \\\n",
    "       .map(plt.scatter, \"PC1\",'PC2') \\\n",
    "       .add_legend()\n",
    "    filename = '../tsne-visualization/'+str(model.perplexity)+'-perplexity.png'\n",
    "    plt.savefig(filename)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have done TSNE for 1000 points of MNIST and for perplexity ranging from 5 to 800. We have stored those images and now we would look at all of them and choose the best one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
